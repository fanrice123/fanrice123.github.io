{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/lock-free-101","result":{"data":{"post":{"__typename":"MdxPost","slug":"/lock-free-101","title":"Lock Free 101","date":"19.07.2020","tags":[{"name":"lock free","slug":"lock-free"},{"name":"concurrent","slug":"concurrent"},{"name":"multicore programming","slug":"multicore-programming"},{"name":"multi-threaded programming","slug":"multi-threaded-programming"}],"description":"Brief Introduction to lock free programming and ABA problem.","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Lock Free 101\",\n  \"date\": \"2020-07-19T00:00:00.000Z\",\n  \"description\": \"Brief Introduction to lock free programming and ABA problem.\",\n  \"tags\": [\"lock free\", \"concurrent\", \"multicore programming\", \"multi-threaded programming\"]\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component '\" + name + \"' was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The way the processor industry is going, is to add more and more cores,\\nbut nobody knows how to program those things.\\nI mean, 2, yeah; 4, not really; eight, forget it.\"), mdx(\"div\", {\n    style: {\n      textAlign: 'right'\n    }\n  }, \" -- \", mdx(\"i\", null, \"Steve Jobs\"))), mdx(\"br\", null), mdx(\"p\", null, \"Multicore programming is not as easy as it sounds. Since I began to learn multi-core programming\\n(to be specific, multi-threaded programming), the synchronisation of multiple threads relies on locking and mutex.\"), mdx(\"p\", null, \"The use case of locking mutex is simple:\"), mdx(\"p\", null, \"Let's say there is a list shared by multiple thread, and each thread needs to perform certain action with the list,\\nit can be adding element, it can be  removing element, checking size, whatever.\\nWell, to synchronise the list modification process, threads are required to lock a mutex.\\nIf locking is successful, the thread proceed to acts towards list;\\nIf locking fails, the thread fall into sleep until mutex become available.\"), mdx(\"h3\", null, \"Sweet!\"), mdx(\"br\", null), mdx(\"br\", null), mdx(\"h3\", null, \"Multi-threaded programming! See you in the next episode!\"), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"h4\", null, \"Wait.....\"), mdx(\"br\", null), mdx(\"p\", null, \"The story isn't over...\"), mdx(\"p\", null, \"Back to the list mentioned, we knows that using mutex to synchronise the list modification works.\\nBut when the parallelism of the list modification scales up, we have a new issue, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"contention\"), \".\"), mdx(\"p\", null, \"You see, if there exists 100 of threads trying to do something to the list at the same time,\\nonly one of them get access to it thanks to the mutex.\\nHowever, it also lets remaining 99 threads fall to sleep until the mutex lock is released.\\nYou might argue that \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"\\\"Well I don't bother with that trade off since I have a machine that support 100 of threads to run in parallel.\\\"\")), \",\\n\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Dude\"), \", you already need 100 of threads to do your job, sooner or later you will bother with this trade off.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"\\\"Ok then, so how about we use multiple mutex?\\\"\"))), mdx(\"p\", null, \"Well, that may work. it depends on how you use the list.\\nIf the list shared accross 100 of threads is used as queue, which is,\\nalways adding element from end, and extracting element from front, then we may design an algorithm to lock only 1 mutex when adding/deleting element from the list,\\nwith an exceptional case where list only has 1 element. In that case, both locks are required to be locked.\"), mdx(\"p\", null, \"***\\\"Great! So I learnt that data sharing accross multiple threads requires some tune to gain performance. Thanks!\\\"\"), mdx(\"br\", null), mdx(\"hr\", null), mdx(\"br\", null), mdx(\"h4\", null, \"You think that solves all the problem?\"), mdx(\"h4\", null, \"Of course... \", mdx(\"em\", {\n    parentName: \"h4\"\n  }, \"No\")), mdx(\"br\", null), mdx(\"br\", null), mdx(\"p\", null, \"In a program that requires resource sharing accross multiple threads, most likely there are more than one\\nresources being shared as well. Which introduces more locks to the logic flow, in turn, increases the chance\\nof getting \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"Dead lock\")), \".\"), mdx(\"p\", null, \"A very simple scenario of deadlock may occurs is as follow:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Imagine there are 2 threads, A & B, and 2 resources being shared, X & Y, guarded by a mutex respectively.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"In execution of thread A, resource X needs to be acquired then subsequently resource Y.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"On the other hand, thread B needs to acquire resource Y first, then resource X.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"When case \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"2\"), \" and \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"3\"), \" happens at the same time...\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"h4\", {\n    parentName: \"li\"\n  }, \"Pfffff! We got Dead lock!\"))), mdx(\"br\", null), mdx(\"br\", null), mdx(\"p\", null, \"Let's be frank, this kind of dead lock is quite easy to solve: you reorder the lock acquiring to consistent sequence.\\nThat is, always lock X then lock Y, or, always lock Y then X.\\nBut this may introduces overhead: if the logic in thread B only requires resouce X in the very end,\\nlocking X in the first place reduces parallelism of the program. In this case, 50% of parallelism gone!\"), mdx(\"p\", null, \"Now, can we do \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"better\")), \"?\"), mdx(\"p\", null, \"\\\"Fxxk it, let's throw all the locks away then.\\\"\"), mdx(\"h5\", null, \"That's right, let's get rid of all locks!!!\"), mdx(\"p\", null, \"\\\"Wait, what? How do we avoid resouce corruption and race condition and other shit?\\\"\"), mdx(\"p\", null, \"Well, we can design the algorithm in a way that the logic of algorithm itself guarantees execution order is correct\\nwithout the involve any mutex locking with the help of one tool -- \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Atomic\")), mdx(\"br\", null), mdx(\"br\", null), mdx(\"hr\", null), mdx(\"br\", null), mdx(\"br\", null), mdx(\"h3\", null, \"What is Atomicity?\"), mdx(\"br\", null), mdx(\"p\", null, \"An atomic operation is an indivisible and irreducible action.\\nLet's look at an example:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-cpp:title=Non-atomic-assignment\"\n  }), \"\\nint global_var = 0;\\n\\nvoid foo(std::integral auto v) {\\n  auto var = 100;\\n  /*\\n   * Doing some task...\\n   *\\n   */\\n  global_var += 10;\\n}\\n\\nint bar(std::integral auto v) {\\n  auto var = 50;\\n  /*\\n   * Doing some task with var...\\n   *\\n   */\\n  return var - global_var;\\n}\\n\")), mdx(\"p\", null, \"As the example above, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"var\"), \" was assigned value \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10\"), \", simple. On the language level, this assignment seems like a single option.\\nHowever, at the lower level, this assignment may involve multiple operation!\"), mdx(\"p\", null, \"Now, imagine 1 thread calls the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"foo()\"), \" and then starts executing and preempted in the middle of executing logic at line \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"7\"), \".\\nAnd then, here comes another thread calling the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"bar()\"), \" function. Who do you think the actual value it reads from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"global_var\"), \"?\"), mdx(\"p\", null, \"The answer is -- \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Undefined\"), \", this is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"race condition\"), \".\"), mdx(\"p\", null, \"To avoid this, we need to make use of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"<atomic>\"), \" library and modify the code abit as follow:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-cpp:title=Atomic-assignment\"\n  }), \"#include <atomic>\\n\\nstd::atomic<int> global_var{10};\\nvoid foo(std::integral auto v) {\\n  auto var = 100;\\n\\n  /*\\n   * Doing some task with var...\\n   *\\n   */\\n\\n  global_var.fech_add(10, std::memory_order::release);\\n}\\n\\nint bar(std::integral auto v) {\\n  auto var = 50;\\n  /*\\n   * Doing some task...\\n   *\\n   */\\n  return var - global_var.load(std::memory_order::consume);\\n}\\n\")), mdx(\"p\", null, \"Duh, with the help of atomic type, the race condition no longer exist as it guarantees every read/write operation to it is always indivisible.\\nSo if a thread executing modified version of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"foo()\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"global_var\"), \" is guarantees to be modified in single operation,\\nand so does \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"global_var\"), \" reading in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"bar()\"), \" not get read in intermidiate state.\"), mdx(\"br\", null), mdx(\"hr\", null), mdx(\"br\", null), mdx(\"p\", null, \"So now, since the program does not has any lock (even though under the hood there is still lock somewhere), it's lock free!\"), mdx(\"h5\", null, \"This is Lock-Free Programming!\"), mdx(\"p\", null, \"We will dive deeper into discussion about the challenges & pitfalls to tackle when practicing lock-free programming.\"), mdx(\"p\", null, \"That's it for today.\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"The way the processor industry is going, is to add more and more cores, \nbut nobody knows how to program those things.\nI mean, 2, yeah;â€¦","timeToRead":3,"banner":null}},"pageContext":{"slug":"/lock-free-101","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["318001574","3787687951","3787687951"]}